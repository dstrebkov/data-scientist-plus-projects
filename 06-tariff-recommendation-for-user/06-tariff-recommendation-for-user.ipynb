{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали.\n",
    "\n",
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до `0.75`. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные модули и открываем файл с данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv('...')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, четыре первых столбца (`calls`, `minutes`, `messages` и `mb_used`) задают входные признаки, на которых нужно научиться предсказывать последний столбец - тарифный план, который больше подойдёт абоненту, описываемому данной строкой входных признаков. Здесь `is_ultra==1` означает, что такому абоненту нужно рекомендовать тариф \"_Ultra_\", а значание `is_ultra==0` говорит об уместности рекомендации тарифа \"_Smart_\". \n",
    "\n",
    "Наличие только двух возможных значений целевого признака говорит о том, что мы будем решать задачу бинарной классификации.\n",
    "\n",
    "Создадим отдельные датафреймы с входными признаками (`features`) и целевым (`target`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used\n",
       "0   40.0   311.90      83.0  19915.42\n",
       "1   85.0   516.75      56.0  22696.96\n",
       "2   77.0   467.66      86.0  21060.45\n",
       "3  106.0   745.53      81.0   8437.39\n",
       "4   66.0   418.74       1.0  14502.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_ultra\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "\n",
    "display(features.head())\n",
    "display(target.to_frame().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя `sklearn.model_selection.train_test_split()` дважды, разделим наши данные на 3 части: тренировочную (`features_train` и `target_train`), валидационную (`features_valid` и `target_valid`) и тестовую (`features_test` и `target_test`).\n",
    "\n",
    "При этом сначала выделим `25%` данных для тестовой части. Оставшиеся `75%` разделим ещё раз, выделяя `80%` от них для тренировочной части и `20%` - для валидационной:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры набора тренировочных входных признаков: (1928, 4)\n",
      "Размеры набора валидационных входных признаков: (482, 4)\n",
      "Размеры набора тестовых входных признаков: (804, 4)\n",
      "---------------------------------------------------------------------------\n",
      "Размеры набора тренировочного целевого признака: (1928,)\n",
      "Размеры набора валидационного целевого признака: (482,)\n",
      "Размеры набора тестового целевого признака: (804,)\n"
     ]
    }
   ],
   "source": [
    "features_train_valid, features_test, target_train_valid, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train_valid, target_train_valid, test_size=0.2, random_state=12345)\n",
    "\n",
    "print(f'Размеры набора тренировочных входных признаков: {features_train.shape}')\n",
    "print(f'Размеры набора валидационных входных признаков: {features_valid.shape}')\n",
    "print(f'Размеры набора тестовых входных признаков: {features_test.shape}')\n",
    "print('-' * 75)\n",
    "print(f'Размеры набора тренировочного целевого признака: {target_train.shape}')\n",
    "print(f'Размеры набора валидационного целевого признака: {target_valid.shape}')\n",
    "print(f'Размеры набора тестового целевого признака: {target_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем натренировать три модели на обучающем наборе и оценить их качество (долю правильных ответов, `accuracy`) на валидационном.\n",
    "\n",
    "Будем использовать следующие три известные мне модели:\n",
    "\n",
    "- логистическую регрессию (`LogisticRegression`);\n",
    "- дерево решений (`DecisionTreeClassifier`);\n",
    "- случайный лес (`RandomForestClassifier`)\n",
    "\n",
    "Сохраняя качественные показатели каждой из этих моделей, выведем их все вместе, чтобы впоследствии выбрать лучшую:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"LogisticRegression\": 0.7365145228215768,\n",
      "    \"DecisionTreeClassifier\": 0.7489626556016598,\n",
      "    \"RandomForestClassifier\": 0.8112033195020747\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def record_score(model, models_accuracies):\n",
    "    \"\"\"Тренирует модель model на тренировочном наборе данных и сохраняет качество предсказаний\n",
    "    обученной модели на валидационном наборе в словаре models_accuracies\"\"\"\n",
    "    # Обучаемся на обучающей выборке\n",
    "    model.fit(features_train, target_train)\n",
    "    # Делаем предсказания на валидационной выборке\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    # Оцениваем качество предсказаний, сохраняя результат в словарь\n",
    "    models_accuracies[model.__class__.__name__] = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "models_accuracies = dict()\n",
    "\n",
    "record_score(LogisticRegression(), models_accuracies)\n",
    "record_score(DecisionTreeClassifier(), models_accuracies)\n",
    "record_score(RandomForestClassifier(), models_accuracies)\n",
    "\n",
    "print(json.dumps(models_accuracies, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что случайный лес (`RandomForestClassifier`) демонстрирует самые высокие показатели `accuracy`. Поэтому, взяв именно эту модель за основу, будем настраивать её гиперпараметры, чтобы добиться по возможности ещё более высокого качества. Настраивать её гиперпараметры будем снова на валидационной выборке, чтобы до последнего \"_не показывать_\" модели тестовые данные, а использовать их уже только при финальном прогоне с выбранными значениями гиперпараметров.\n",
    "\n",
    "Чтобы ускорить и как-то автоматизировать процесс перебора возможных значений гиперпараметров, будем использовать рандомизированный поиск среди всевозможных значений, который реализован в `RandomizedSearchCV`. В частности, будем искать лучшее значение среди следующих параметров:\n",
    "\n",
    "- `n_estimators` - количество деревьев в случайном лесу;\n",
    "- `max_depth` - максимальная допустимая глубина дерева;\n",
    "- `min_samples_split` - минимальное количество обучающих примеров для выполнения разбиения в нелистовом узле;\n",
    "- `min_samples_leaf` - минимальное количество обучающих примеров, которое необходимо, чтобы узел дерева мог бы быть листовым.\n",
    "\n",
    "Кросс-валидацию будем делать с использованием 15 разбиений (`cv=15`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальное достигнутое качество модели при рандомизированном поиске:\n",
      "\t 0.8203467908902692\n",
      "Значения гиперпараметров, обеспечивающие это качество:\n",
      "\t {'n_estimators': 100, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "param_grid=[\n",
    "    {\n",
    "        'n_estimators': [50, 100, 150, 200],\n",
    "        'max_depth': range(1, 20),\n",
    "        'min_samples_split': range(1, 20),\n",
    "        'min_samples_leaf': range(1, 20)\n",
    "    }]\n",
    "\n",
    "rs = RandomizedSearchCV(\n",
    "                 estimator=RandomForestClassifier(random_state=12345),\n",
    "                 param_distributions=param_grid,\n",
    "                 scoring='accuracy',\n",
    "                 cv=15,\n",
    "                 random_state=12345)\n",
    "\n",
    "rs.fit(features_train_valid, target_train_valid)\n",
    "print(f'Максимальное достигнутое качество модели при рандомизированном поиске:\\n\\t {rs.best_score_}')\n",
    "print(f'Значения гиперпараметров, обеспечивающие это качество:\\n\\t {rs.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда были выбраны наиболее оптимальные значения гиперпараметров, создадим модель случайного леса, передавая эти оптимальные значения в качестве параметров.\n",
    "\n",
    "Наконец, оценим качество нашей модели теперь уже на тестовой выборке, чтобы проверить удалось ли нам преодолеть допустимое и приемлемое значение доли правильных ответов - `0.75`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Качество на тестовой выборке\n",
      "\t: 0.8022388059701493\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=12345,\n",
    "                               n_estimators=rs.best_params_['n_estimators'],\n",
    "                               min_samples_split=rs.best_params_['min_samples_split'],\n",
    "                               min_samples_leaf=rs.best_params_['min_samples_leaf'],\n",
    "                               max_depth=rs.best_params_['max_depth'])\n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions_test = model.predict(features_test)\n",
    "\n",
    "test_accuracy = accuracy_score(target_test, predictions_test)\n",
    "print(f'Качество на тестовой выборке:\\n\\t {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что качество на тестовой выборке - `0.8` - превосходит приемлемое значение (`0.75`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, попробуем проверить обученную модель на адекватность. Если я правильно понял обсуждение в нашем Slack-канале \"`projects`\", нам нужно сравнить качество нашей модели с качеством лучшей константной модели - модели, которая для любого входа предсказывает метку наиболее часто встречающегося на обучающей выборке класса.\n",
    "\n",
    "Начнём с того, что определим, какой класс на обучающем наборе является самым часто встречающимся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество абонентов тарифа \"Smart\" (значение метки 0) : 1338\n",
      "Количество абонентов тарифа \"Ultra\" (значение метки 1) : 590\n"
     ]
    }
   ],
   "source": [
    "value_counts = target_train.value_counts()\n",
    "smart_count = value_counts[0]\n",
    "ultra_count = value_counts[1]\n",
    "print(f'Количество абонентов тарифа \"Smart\" (значение метки 0) : {smart_count}')\n",
    "print(f'Количество абонентов тарифа \"Ultra\" (значение метки 1) : {ultra_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можем видеть, что для нас наиболее часто встречающимся классом является `0` (тариф \"_Smart_\"). Попробуем оценить, какого качества модели мы могли бы добиться (и на обучающем, и на тестовом наборах), если бы предсказывали наиболее часто встречающийся класс:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных ответов для константной модели:\n",
      "\n",
      "\t- на обучающем наборе : 0.6939834024896265\n",
      "\t- на тестовом наборе  : 0.7002487562189055\n"
     ]
    }
   ],
   "source": [
    "dumb_train = np.full((target_train.shape), 0)\n",
    "dumb_test = np.full((target_test.shape), 0)\n",
    "\n",
    "print(f'Доля правильных ответов для константной модели:\\n')\n",
    "print(f'\\t- на обучающем наборе : {accuracy_score(target_train, dumb_train)}')\n",
    "print(f'\\t- на тестовом наборе  : {accuracy_score(target_test, dumb_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что качество константной модели составляет около `0.7`. Исходя из этого, можно более ясно понять выбор приемлемого значения в `0.75` - это примерно на `5%` лучше совсем тривиальной модели, которая всегда предсказывает одно и то же значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист готовности проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставьте 'x' в выполненных пунктах. Далее нажмите Shift+Enter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Jupyter Notebook открыт\n",
    "- [x] Весь код исполняется без ошибок\n",
    "- [x] Ячейки с кодом расположены в порядке исполнения\n",
    "- [x] Выполнено задание 1: данные загружены и изучены\n",
    "- [x] Выполнено задание 2: данные разбиты на три выборки\n",
    "- [x] Выполнено задание 3: проведено исследование моделей\n",
    "    - [x] Рассмотрено больше одной модели\n",
    "    - [x] Рассмотрено хотя бы 3 значения гипепараметров для какой-нибудь модели\n",
    "    - [x] Написаны выводы по результатам исследования\n",
    "- [x] Выполнено задание 3: Проведено тестирование\n",
    "- [x] Удалось достичь accuracy не меньше 0.75"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
